
AI Scaling Laws Emerge

With their vast resources, the Baidu team could throw computing power and data at problems in an attempt to improve their outcomes. They saw remarkable results. [curious] In their experiments, Amodei and his colleagues found that AI’s performance improved meaningfully as they added more of these ingredients. The team released a paper on speech recognition that showed that model size directly correlated with performance. “It had a big impact on me, because I saw these very smooth trends,” Amodei says.

Amodei’s early work at Baidu contributed to what’s known as the AI “scaling laws,” which are really more of an observation. The scaling laws state that increasing computing power, data, and model size in AI training leads to predictable performance improvements. [excited] Scaling everything up, in other words, makes AI better, no novel methods needed. “This was, to me, the most significant discovery I’ve seen in my life,” Diamos tells me.

To this day, Amodei is perhaps the purest believer in the scaling laws among AI research leaders. While peers like Demis Hassabis and Yann LeCun suggest the AI industry needs further breakthroughs to reach human-level artificial intelligence, Amodei speaks with a certainty — though not complete — that the path forward is clear. And as the industry erects massive data centers the size of small cities, he sees exceptionally powerful AI fast approaching. [whispers] “I see this exponential,” he says. “When you’re on an exponential, you can really get fooled by it. Two years away from when the exponential goes totally crazy it looks like it’s just starting.”

At Baidu, the AI team’s progress became seeds of its undoing. Turf battles broke out within the company over control of its increasingly valuable technology, know-how, and resources. Eventually, meddling from powerbrokers in China sparked a talent exodus and the lab fell apart. [sighs] Andrew Ng declined to comment.

Elon Musk invited Amodei and a number of leading AI researchers to a now-famous dinner at the Rosewood hotel in Menlo Park. Sam Altman, Greg Brockman, and Ilya Sutskever all attended. Seeing AI’s emerging potential, and concerned Google could solidify control over it, Musk decided to fund a new competitor, which became OpenAI. Altman, Brockman, and Sutskever co-founded the new research house with Musk.

Amodei thought about joining, felt unsure about the fledgling organization, and went to Google Brain instead. After ten months stuck in large-company morass at Google, Amodei reconsidered. He joined OpenAI in 2016, and got to work on AI safety. He’d grown interested in safety at Google, where he worried about the rapidly improving technology’s capacity for harm and co-authored a paper on its potential for bad behavior.

As Amodei settled in at OpenAI, his former Google colleagues introduced the transformer model in a paper called “Attention is All You Need.” The transformer enabled faster training and much larger models than prior methods. Despite the discovery’s great potential, Google mostly sat on it. OpenAI, meanwhile, got to work. It released its first large language model called “GPT” in 2018. The model generated often-broken text but still demonstrated meaningful improvement. Amodei, who’d become a research director at OpenAI, got directly involved in the next iteration, GPT-2, which was effectively the same model as GPT, just bigger. The OpenAI team fine-tuned GPT-2 with a technique called reinforcement learning with human feedback, something Amodei helped pioneer, which helped guide its values. GPT-2 delivered much better results than GPT, showing an ability to paraphrase, write, and answer questions somewhat coherently. Language models soon became the focal point at OpenAI.

As Amodei’s profile increased within OpenAI, so did the controversy around him. A prolific writer, he’d produce long documents about values and technology, which some colleagues saw as inspirational but others saw as flag planting and heavy handed. (One such memo: an exploration of “M” companies vs. “P” companies, where Ms provide market-focused goods and Ps provide public-focused goods). Amodei, to some, was also too focused on maintaining secrecy around the technology’s potential and collaborating with the government to address it. And he could be a bit abrasive, sometimes disparaging projects…